p8105_hw2_as6447
================
Armaan Sodhi
2022-10-03

\##Problem 0

``` r
library(tidyverse)
```

    ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──
    ## ✔ ggplot2 3.3.6      ✔ purrr   0.3.4 
    ## ✔ tibble  3.1.8      ✔ dplyr   1.0.10
    ## ✔ tidyr   1.2.0      ✔ stringr 1.4.1 
    ## ✔ readr   2.1.2      ✔ forcats 0.5.2 
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()

``` r
library(readxl)
library(lubridate)
```

    ## 
    ## Attaching package: 'lubridate'
    ## 
    ## The following objects are masked from 'package:base':
    ## 
    ##     date, intersect, setdiff, union

\##Problem 1

``` r
NYC_transit_data = 
  read_csv('data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv',
           col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) %>%
  janitor::clean_names()%>%
  select( 
          line, station_name, station_latitude, station_longitude, 
          entry, vending, exit_only, entrance_type, ada, starts_with('route'))%>%
  mutate(entry=if_else(entry=='YES',TRUE,FALSE))

nrow(NYC_transit_data)
```

    ## [1] 1868

``` r
ncol(NYC_transit_data)
```

    ## [1] 20

From the use of `nrow` and `ncol` we find that there are 20 columns
(variables) and 1868 rows (observations). It provides geographic data
about where stations are located (ie station name, longitude/latitude),
the characteristics of those locations (ie what type of entry do they
have, are they ADA compliant, are there vending machines in the
station), and the subway lines that run through the stations and the
routes they follow. Cleaning the data required converting the variables
to snake case (so that I can actually manipulate the variables without
increasing my blood pressure), then I restricted the data set to only
the required variables. Finally, I converted the entry variable to a
logical variable.

The data itself is not tidy considering the routes variables which are
in `pivot_wider` so that each route is its own variable. It would be
more efficient and “tidier” to `Pivot_longer`.

``` r
NYC_transit_data %>% distinct(line,station_name)
```

    ## # A tibble: 465 × 2
    ##    line     station_name            
    ##    <chr>    <chr>                   
    ##  1 4 Avenue 25th St                 
    ##  2 4 Avenue 36th St                 
    ##  3 4 Avenue 45th St                 
    ##  4 4 Avenue 53rd St                 
    ##  5 4 Avenue 59th St                 
    ##  6 4 Avenue 77th St                 
    ##  7 4 Avenue 86th St                 
    ##  8 4 Avenue 95th St                 
    ##  9 4 Avenue 9th St                  
    ## 10 4 Avenue Atlantic Av-Barclays Ctr
    ## # … with 455 more rows

There are 465 unique stations (found in the console after running the
above code chunk)

``` r
NYC_transit_data %>% filter(ada == TRUE) %>% distinct(line,station_name)
```

    ## # A tibble: 84 × 2
    ##    line            station_name                  
    ##    <chr>           <chr>                         
    ##  1 4 Avenue        Atlantic Av-Barclays Ctr      
    ##  2 4 Avenue        DeKalb Av                     
    ##  3 4 Avenue        Pacific St                    
    ##  4 42nd St Shuttle Grand Central                 
    ##  5 6 Avenue        34th St                       
    ##  6 6 Avenue        47-50th Sts Rockefeller Center
    ##  7 6 Avenue        Church Av                     
    ##  8 63rd Street     21st St                       
    ##  9 63rd Street     Lexington Av                  
    ## 10 63rd Street     Roosevelt Island              
    ## # … with 74 more rows

84 stations are found to be ADA Compliant.

``` r
NYC_transit_data %>% 
  filter(vending =='NO')%>%
  pull(entry)%>%
  mean()
```

    ## [1] 0.3770492

The proportion of station entrances/exit without vending allow entrances
is 0.377049 (37.70% of station entrances and exits are without vending
allowed)

``` r
NYC_transit_data %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A") %>% 
  select(station_name, line) %>% 
  distinct
```

    ## # A tibble: 60 × 2
    ##    station_name                  line           
    ##    <chr>                         <chr>          
    ##  1 Times Square                  42nd St Shuttle
    ##  2 125th St                      8 Avenue       
    ##  3 145th St                      8 Avenue       
    ##  4 14th St                       8 Avenue       
    ##  5 168th St - Washington Heights 8 Avenue       
    ##  6 175th St                      8 Avenue       
    ##  7 181st St                      8 Avenue       
    ##  8 190th St                      8 Avenue       
    ##  9 34th St                       8 Avenue       
    ## 10 42nd St                       8 Avenue       
    ## # … with 50 more rows

``` r
NYC_transit_data %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A", ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

    ## # A tibble: 17 × 2
    ##    station_name                  line            
    ##    <chr>                         <chr>           
    ##  1 14th St                       8 Avenue        
    ##  2 168th St - Washington Heights 8 Avenue        
    ##  3 175th St                      8 Avenue        
    ##  4 34th St                       8 Avenue        
    ##  5 42nd St                       8 Avenue        
    ##  6 59th St                       8 Avenue        
    ##  7 Inwood - 207th St             8 Avenue        
    ##  8 West 4th St                   8 Avenue        
    ##  9 World Trade Center            8 Avenue        
    ## 10 Times Square-42nd St          Broadway        
    ## 11 59th St-Columbus Circle       Broadway-7th Ave
    ## 12 Times Square                  Broadway-7th Ave
    ## 13 8th Av                        Canarsie        
    ## 14 Franklin Av                   Franklin        
    ## 15 Euclid Av                     Fulton          
    ## 16 Franklin Av                   Fulton          
    ## 17 Howard Beach                  Rockaway

There are 60 stations and lines that serve the A train and 17 stations
that are ADA compliant.

\##Problem 2

``` r
Mr_Trash_Wheel = 
  readxl::read_excel("data/Trash Wheel Collection Data.xlsx", "Mr. Trash Wheel", range = "A2:N549")%>%
  janitor::clean_names()%>%
  drop_na()%>%
  mutate(
    sports_balls=round(sports_balls),
    sports_balls= as.integer(sports_balls),
    sheet_type= 'Mr_trash_wheel'
    )
```

This sheet initially has 548 observations and we have been given 16
variables, two of which where empty variables. We removed these
variables and then ended up with only 14 variables. We omitted any rows
that did not include dumpster-specific data. I then rounded and then
converted it to an integer.

``` r
Professor_Trash_Wheel = 
  readxl::read_excel("data/Trash Wheel Collection Data.xlsx", "Professor Trash Wheel", range = "A2:M96")%>%
  janitor::clean_names()%>%
  drop_na()%>%
  mutate(
    year = as.character(year),
    sheet_type = 'Professor_trash_wheel'
  )
```

Please note that I converted the year variable to a character here so
that the two data sets are consistent with each other. I then created
the `sheet_type` variable so that I could properly differentiate between
the two when I merged them later. I dropped any rows that did not
include dumpster-specific data as well. And converted the variables to
snake case.

``` r
trash_wheel_bind =
  bind_rows(Professor_Trash_Wheel, Mr_Trash_Wheel)
```

``` r
trash_wheel_bind %>% 
  filter(sheet_type == 'Professor_trash_wheel')%>%
  pull(weight_tons)%>%
  sum()
```

    ## [1] 162.54

``` r
trash_wheel_bind %>% 
  filter(sheet_type == 'Mr_trash_wheel', year=='2020')%>%
  pull(sports_balls)%>%
  sum()
```

    ## [1] 856

This consisted of data about a water wheel of two different types. There
was two different wheels,`Mr_Trash_Wheel` (468 rows and 15 columns) and
`Professor_Trash_Wheel` (82 rows and 14 variables). Key variables would
include the `dumpster`(dumpster number), `weight_tons` (how much weight
of trash in tons ), `sports_balls`(how many sports balls were
collected), and `volume_cubic_yards` (the volume of trash in cubic yards
that is thrown away). When the two are binded together it creates a
`trash_wheel_bind` (568 rows and 15 columns). The total weight of trash
collected by Professor Trash Wheel was 162.54 tons. In 2020,
`Mr. Trash Wheel` collected 856 sports balls.

\##Problem 3

``` r
pols_month_data = 
  read_csv('data/pols-month.csv')%>%
  janitor::clean_names()%>%
  separate(col = mon, into=c('year','month','day'), sep='-')%>%
  mutate(
    month = as.integer(month),
    month = month.abb[month],
    year = as.integer(year),
    president = case_when( 
      prez_dem == 1 ~ 'dem',
      prez_gop == 1 ~ 'gop',
      prez_gop == 2 ~ 'unknown'))%>%
  select(-day,-prez_dem,-prez_gop)
```

    ## Rows: 822 Columns: 9
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl  (8): prez_gop, gov_gop, sen_gop, rep_gop, prez_dem, gov_dem, sen_dem, r...
    ## date (1): mon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

I separated the date data by year,month, and day. Then used mutate to
change the month from numbered month to character month as well as
changing year to numeric (so I could merge the datasets). Then created
the president variable by using `case_when` to combine `prez_dem` and
`prez_gop`. Finally, I used `select` to remove `day,prez_dem,prez_gop`.

``` r
snp_stock_market_index = read_csv('data/snp.csv')%>%
  janitor::clean_names()%>%
  separate(col = date, into = c('month','day','year'), sep='/')%>%
  mutate(
    month = as.integer(month),
    month = month.abb[month],
    year = as.integer(year),
    closing_value = close,
    year_fix= case_when( year<22 ~ 2000,
                         year>22 ~ 1900),
    year= year+year_fix )%>%
  relocate (year,month)%>%
select(-day,-year_fix,-close)
```

    ## Rows: 787 Columns: 2
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (1): date
    ## dbl (1): close
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

I separated the date data by year,month, and day. Then used mutate to
change the month from numbered month to character month as well as
changing year to numeric (so I could merge the datasets).Renamed `close`
to `closing_value`. Then I fixed `year` variable as it was 2 digits
instead of 4 digits by adding either 2000 or 1900 if the year was
greater than or equal to 22. Then the year and month were relocated to
the front and finally `day`, `year_fix`, and the original `close` value
was deleted.

``` r
unemployment_data=read_csv('data/unemployment.csv')%>%
  janitor::clean_names()%>%
pivot_longer(
  jan:dec,
  names_to = 'month', 
    values_to = 'unemployment_percent'
)%>%
  mutate(
    month=str_to_title(month)
  )
```

    ## Rows: 68 Columns: 13
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (13): Year, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

For the `unemployment_data` by using the `pivot_longer` function then
selected january to december creating two variables `month` and
`unemployment_percent`. Finally `month` was made to have the first
letter capitalized.

``` r
overall_merged_Data =
  left_join(pols_month_data,snp_stock_market_index)%>%
  left_join(.,unemployment_data)
```

    ## Joining, by = c("year", "month")
    ## Joining, by = c("year", "month")

These datasheets consist of election data. It consists of information on
politicians at the national level at a month level (ie `pols-months`-822
rows and 9 columns), the S&P stock index (`snp_stock_market_index`- 787
rows and 3 columns), and the unemployment percentages per month
(`unemployment_data`-816 rows and 3 columns). The combined data consists
of 822 observations with 11 different variables. These variables include
`year` (1947-2022), `month`, `closing_value` (closing value of S&P
index), and `president` (which political party was the president
affiliated with). There were also variables for the number of:
governor’s, representatives, and senators that were affiliated with a
particular political party.
